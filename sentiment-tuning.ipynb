{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset_name = \"carblacac/twitter-sentiment-analysis\"\n",
    "train_len = 30000\n",
    "test_len = 50\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "train_df = pd.DataFrame(dataset['train'][:train_len])\n",
    "test_df = pd.DataFrame(dataset['test'][:test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@fa6ami86 so happy that salman won.  btw the 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@phantompoptart .......oops.... I guess I'm ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@bradleyjp decidedly undecided. Depends on the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Mountgrace lol i know! its so frustrating isn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kathystover Didn't go much of any where - Lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  feeling\n",
       "0  @fa6ami86 so happy that salman won.  btw the 1...        0\n",
       "1  @phantompoptart .......oops.... I guess I'm ki...        0\n",
       "2  @bradleyjp decidedly undecided. Depends on the...        1\n",
       "3  @Mountgrace lol i know! its so frustrating isn...        1\n",
       "4  @kathystover Didn't go much of any where - Lif...        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "      <th>input_1</th>\n",
       "      <th>input_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@fa6ami86 so happy that salman won.  btw the 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>Carefully read the following tweet. Assess the...</td>\n",
       "      <td>Analyze the mood conveyed in the tweet below, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@phantompoptart .......oops.... I guess I'm ki...</td>\n",
       "      <td>0</td>\n",
       "      <td>Carefully read the following tweet. Assess the...</td>\n",
       "      <td>Analyze the mood conveyed in the tweet below, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@bradleyjp decidedly undecided. Depends on the...</td>\n",
       "      <td>1</td>\n",
       "      <td>Carefully read the following tweet. Assess the...</td>\n",
       "      <td>Analyze the mood conveyed in the tweet below, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Mountgrace lol i know! its so frustrating isn...</td>\n",
       "      <td>1</td>\n",
       "      <td>Carefully read the following tweet. Assess the...</td>\n",
       "      <td>Analyze the mood conveyed in the tweet below, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kathystover Didn't go much of any where - Lif...</td>\n",
       "      <td>1</td>\n",
       "      <td>Carefully read the following tweet. Assess the...</td>\n",
       "      <td>Analyze the mood conveyed in the tweet below, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  feeling  \\\n",
       "0  @fa6ami86 so happy that salman won.  btw the 1...        0   \n",
       "1  @phantompoptart .......oops.... I guess I'm ki...        0   \n",
       "2  @bradleyjp decidedly undecided. Depends on the...        1   \n",
       "3  @Mountgrace lol i know! its so frustrating isn...        1   \n",
       "4  @kathystover Didn't go much of any where - Lif...        1   \n",
       "\n",
       "                                             input_1  \\\n",
       "0  Carefully read the following tweet. Assess the...   \n",
       "1  Carefully read the following tweet. Assess the...   \n",
       "2  Carefully read the following tweet. Assess the...   \n",
       "3  Carefully read the following tweet. Assess the...   \n",
       "4  Carefully read the following tweet. Assess the...   \n",
       "\n",
       "                                             input_2  \n",
       "0  Analyze the mood conveyed in the tweet below, ...  \n",
       "1  Analyze the mood conveyed in the tweet below, ...  \n",
       "2  Analyze the mood conveyed in the tweet below, ...  \n",
       "3  Analyze the mood conveyed in the tweet below, ...  \n",
       "4  Analyze the mood conveyed in the tweet below, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = {\n",
    "    'instruction_1': \"Carefully read the following tweet. Assess the overall sentiment expressed by considering the choice of words and the tone. Label the tweet with '1' if the overall sentiment is positive, reflecting happiness or satisfaction, and '0' if it reflects a negative sentiment such as sadness or anger.\",\n",
    "    'instruction_2': \"Analyze the mood conveyed in the tweet below, taking into account the language, emojis (if any), and contextual cues. Label the mood as '1' if the tweet communicates a positive, cheerful, or optimistic tone, and '0' if it conveys negativity, pessimism, or discontent.\"\n",
    "}\n",
    "\n",
    "def format_instruction(row, instruction):\n",
    "    return f\"{instruction}\\n\\n### Tweet: '{row['text']}'\\n\\n### Sentiment: {row['feeling']}\"\n",
    "\n",
    "train_df['input_1'] = train_df.apply(lambda x: format_instruction(x, instructions['instruction_1']), axis=1)\n",
    "train_df['input_2'] = train_df.apply(lambda x: format_instruction(x, instructions['instruction_2']), axis=1)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carefully read the following tweet. Assess the overall sentiment expressed by considering the choice of words and the tone. Label the tweet with '1' if the overall sentiment is positive, reflecting happiness or satisfaction, and '0' if it reflects a negative sentiment such as sadness or anger.\n",
      "\n",
      "### Tweet: '@fa6ami86 so happy that salman won.  btw the 14sec clip is truely a teaser'\n",
      "\n",
      "### Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.iloc[0]['input_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'mistralai/Mistral-7B-v0.1'\n",
    "new_model = 'models/Mistral-7B-sentiment-tuned'\n",
    "output_dir = 'results/Mistral-7B-sentiment-tuned'\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=16,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"all\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "hf_dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=hf_dataset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"input_2\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [468/468 34:13, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.703300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=468, training_loss=0.7216785382001828, metrics={'train_runtime': 2059.9567, 'train_samples_per_second': 14.563, 'train_steps_per_second': 0.227, 'total_flos': 1.486091600168878e+17, 'train_loss': 0.7216785382001828, 'epoch': 0.9984})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/Mistral-7B-sentiment-tuned/tokenizer_config.json',\n",
       " 'models/Mistral-7B-sentiment-tuned/special_tokens_map.json',\n",
       " 'models/Mistral-7B-sentiment-tuned/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
